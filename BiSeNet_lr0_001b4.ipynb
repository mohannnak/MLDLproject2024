{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f33gyqE2K2JJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xJu_XvBdZAgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install torch torchvision torchmetrics thop\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhbiuW2BU9Ec",
        "outputId": "e4ef8689-0c11-4c9f-8545-382a4f05943a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.4.0.post0)\n",
            "Requirement already satisfied: thop in /usr/local/lib/python3.10/dist-packages (0.1.1.post2209072238)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.11.3.post0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ijKMTUvHT6Ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torchprofile"
      ],
      "metadata": {
        "id": "W2od11trTFic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5ea2fca-2543-45d8-e4f8-9155f0bd0bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchprofile in /usr/local/lib/python3.10/dist-packages (0.0.4)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.10/dist-packages (from torchprofile) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from torchprofile) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.4 in /usr/local/lib/python3.10/dist-packages (from torchprofile) (0.18.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4->torchprofile) (12.5.82)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.4->torchprofile) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4->torchprofile) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4->torchprofile) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U fvcore"
      ],
      "metadata": {
        "id": "kP_mEN9aTPSC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c362b8c-1fdf-44af-a393-71d637c3aabb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.10/dist-packages (0.1.5.post20221221)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore) (1.25.2)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from fvcore) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore) (6.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fvcore) (4.66.4)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from fvcore) (2.4.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from fvcore) (9.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fvcore) (0.9.0)\n",
            "Requirement already satisfied: iopath>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from fvcore) (0.1.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from iopath>=0.1.7->fvcore) (4.12.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath>=0.1.7->fvcore) (2.10.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2NuilIoSNyu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "import os\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "#from torchmetrics import JaccardIndex\n",
        "#from thop import profile, clever_format\n",
        "import time\n",
        "\n",
        "#from fvcore.nn import FlopCountAnalysis, flop_count_table\n",
        "#import torchprofile\n",
        "\n",
        "\n",
        "\n",
        "from torchmetrics import JaccardIndex\n",
        "from thop import profile, clever_format\n",
        "import time\n",
        "\n",
        "from fvcore.nn import FlopCountAnalysis, flop_count_table\n",
        "import torchprofile\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KdsXf207N8gV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dBTPWcocSrR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CityscapesDataset(Dataset):\n",
        "  def __init__(self, root_dir, im_transform ):\n",
        "\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    root_dir (string): Directory with all the images.\n",
        "    transform (callable, optional): Optional transform to be applied on a sample.\n",
        "    \"\"\"\n",
        "    self.root_dir = root_dir\n",
        "    self.im_transform = im_transform\n",
        "    #self.lab_transform = lab_transform\n",
        "    self.images = []\n",
        "    for subdir, dirs, files in os.walk(root_dir):\n",
        "      for file in files:\n",
        "        if file.endswith('_gtFine_color.png'):\n",
        "          self.images.append(os.path.join(subdir, file))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_name = self.images[idx]\n",
        "    image = Image.open(img_name).convert('RGB')\n",
        "    label_name = img_name.replace('_gtFine_color.png', '_gtFine_labelTrainIds.png')  #labelTrainIds\n",
        "    label = Image.open(label_name)\n",
        "\n",
        "\n",
        "    # Resize label using nearest-neighbor interpolation\n",
        "    label = TF.resize(label, (1024, 512), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "    label = np.array(label)  # Convert to numpy array\n",
        "    label = torch.from_numpy(label).long()  # Convert to LongTensor\n",
        "\n",
        "\n",
        "    if self.im_transform:\n",
        "\n",
        "      image = self.im_transform(image)\n",
        "\n",
        "    # if self.lab_transform:\n",
        "    #   label = self.lab_transform(label)\n",
        "\n",
        "    return image, label\n",
        "\n"
      ],
      "metadata": {
        "id": "Z3HtXvfzRp1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JYwHw7jwvTI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cityscapes Dataset load"
      ],
      "metadata": {
        "id": "zNWddRGrt1kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/Drive')\n",
        "get_ipython().system('/content/Drive/MyDrive/Cityscapes/Cityspaces')"
      ],
      "metadata": {
        "id": "E4k4DE0eEjwr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ce8facc-9303-442f-8c14-ce87dedcc2a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/Drive; to attempt to forcibly remount, call drive.mount(\"/content/Drive\", force_remount=True).\n",
            "/bin/bash: line 1: /content/Drive/MyDrive/Cityscapes/Cityspaces: Is a directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_ipython().system('/content/Drive/MyDrive/Cityscapes/Cityspaces')"
      ],
      "metadata": {
        "id": "wqu-NDJHFkGk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1235587-7e77-49c7-e1f9-55cbe6e5d720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: /content/Drive/MyDrive/Cityscapes/Cityspaces: Is a directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Clone**"
      ],
      "metadata": {
        "id": "_09FKOE7XLEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the GitHub repository\n",
        "!git clone https://github.com/Gabrysse/MLDL2024_project1.git\n",
        "%cd MLDL2024_project1"
      ],
      "metadata": {
        "id": "HPllYnf-NPeU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0ef92a6-afa8-49e6-b461-c0190e9e6b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MLDL2024_project1'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 34 (delta 8), reused 4 (delta 4), pack-reused 16\u001b[K\n",
            "Receiving objects: 100% (34/34), 12.06 KiB | 12.06 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n",
            "/content/MLDL2024_project1/MLDL2024_project1/MLDL2024_project1/MLDL2024_project1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "54MyjXbIZrqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tdvvn2sDZr2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Navigate to the project directory\n",
        "%cd MLDL2024_project1"
      ],
      "metadata": {
        "id": "7kkLfxwKNZ5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aef34631-ac6b-4a9c-91c0-b68d7c00bea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'MLDL2024_project1'\n",
            "/content/MLDL2024_project1/MLDL2024_project1/MLDL2024_project1/MLDL2024_project1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from models.bisenet.build_bisenet import BiSeNet"
      ],
      "metadata": {
        "id": "Vi5RIWMWOJba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "maAKFDMmv7V6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "PAC9VIa40hM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6NlAkhe7VNNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parameters**"
      ],
      "metadata": {
        "id": "mnnzlL6eVNsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training parameters\n",
        "epochs = 25\n",
        "learning_rate =0.001\n",
        "batch_size = 4\n",
        "train_resolution = (1024, 512)\n",
        "test_resolution = (1024, 512)\n"
      ],
      "metadata": {
        "id": "032jMg_kVQWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LjeViRqLVQ7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Loader**"
      ],
      "metadata": {
        "id": "UszT9qhVJl44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a transform if you need to preprocess the images\n",
        "transformed_dataset = CityscapesDataset(root_dir='/content/Drive/MyDrive/Cityscapes/Cityspaces/gtFine/train',\n",
        "im_transform=transforms.Compose([\n",
        "\n",
        "transforms.ToTensor(),\n",
        "transforms.Resize(train_resolution),\n",
        "\n",
        "]), )\n",
        "\n",
        "\n",
        "train_loader = DataLoader(transformed_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "print(len(train_loader))\n"
      ],
      "metadata": {
        "id": "gjWP2n62UBn3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a0fe4d5-25ea-4495-d4bf-c5299376cb78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load the BiSeNet model\n",
        "model = BiSeNet(num_classes=19,context_path='resnet101')   #BiSeNet\n",
        "\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "# Define the CrossEntropyLoss with ignore_index set to 255\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "F0Yr3sirzs00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the metric for mIoU\n",
        "miou_metric = JaccardIndex(num_classes=19, task='multiclass' , ignore_index=255).to(device)\n"
      ],
      "metadata": {
        "id": "8fNiWtGSzs8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute latency\n",
        "def measure_latency(model, input_tensor, repetitions=100):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        start = time.time()\n",
        "        for _ in range(repetitions):\n",
        "            _ = model(input_tensor)\n",
        "        end = time.time()\n",
        "    latency = (end - start) / repetitions\n",
        "    return latency\n",
        "\n",
        "\n",
        "\n",
        "# Measure FLOPs and number of parameters\n",
        "\n",
        "\n",
        "dummy_input = torch.randn(1, 3, 1024, 512).to(device)\n",
        "\n",
        "height = 1024\n",
        "width = 512\n",
        "image =torch.zeros((1,3, height, width)).to(device)   # torch.randn(1,3, 1024, 512).to(device)#\n",
        "\n",
        "model.eval()\n",
        "flops = FlopCountAnalysis(model, image)\n",
        "print(flop_count_table(flops))\n",
        "\n"
      ],
      "metadata": {
        "id": "e8p-LLxDzMNb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99d613a0-bfc2-45d9-94fc-04d6b5ed2ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| module                                      | #parameters or shape   | #flops     |\n",
            "|:--------------------------------------------|:-----------------------|:-----------|\n",
            "| model                                       | 50.801M                | 91.923G    |\n",
            "|  saptial_path                               |  0.371M                |  5.088G    |\n",
            "|   saptial_path.convblock1                   |   1.856K               |   0.243G   |\n",
            "|    saptial_path.convblock1.conv1            |    1.728K              |    0.226G  |\n",
            "|    saptial_path.convblock1.bn               |    0.128K              |    16.777M |\n",
            "|   saptial_path.convblock2                   |   73.984K              |   2.424G   |\n",
            "|    saptial_path.convblock2.conv1            |    73.728K             |    2.416G  |\n",
            "|    saptial_path.convblock2.bn               |    0.256K              |    8.389M  |\n",
            "|   saptial_path.convblock3                   |   0.295M               |   2.42G    |\n",
            "|    saptial_path.convblock3.conv1            |    0.295M              |    2.416G  |\n",
            "|    saptial_path.convblock3.bn               |    0.512K              |    4.194M  |\n",
            "|  context_path.features                      |  44.549M               |  81.835G   |\n",
            "|   context_path.features.conv1               |   9.408K               |   1.233G   |\n",
            "|    context_path.features.conv1.weight       |    (64, 3, 7, 7)       |            |\n",
            "|   context_path.features.bn1                 |   0.128K               |   16.777M  |\n",
            "|    context_path.features.bn1.weight         |    (64,)               |            |\n",
            "|    context_path.features.bn1.bias           |    (64,)               |            |\n",
            "|   context_path.features.layer1              |   0.216M               |   7.072G   |\n",
            "|    context_path.features.layer1.0           |    75.008K             |    2.458G  |\n",
            "|    context_path.features.layer1.1           |    70.4K               |    2.307G  |\n",
            "|    context_path.features.layer1.2           |    70.4K               |    2.307G  |\n",
            "|   context_path.features.layer2              |   1.22M                |   10.802G  |\n",
            "|    context_path.features.layer2.0           |    0.379M              |    3.92G   |\n",
            "|    context_path.features.layer2.1           |    0.28M               |    2.294G  |\n",
            "|    context_path.features.layer2.2           |    0.28M               |    2.294G  |\n",
            "|    context_path.features.layer2.3           |    0.28M               |    2.294G  |\n",
            "|   context_path.features.layer3              |   26.09M               |   54.242G  |\n",
            "|    context_path.features.layer3.0           |    1.512M              |    3.906G  |\n",
            "|    context_path.features.layer3.1           |    1.117M              |    2.288G  |\n",
            "|    context_path.features.layer3.2           |    1.117M              |    2.288G  |\n",
            "|    context_path.features.layer3.3           |    1.117M              |    2.288G  |\n",
            "|    context_path.features.layer3.4           |    1.117M              |    2.288G  |\n",
            "|    context_path.features.layer3.5           |    1.117M              |    2.288G  |\n",
            "|    context_path.features.layer3.6           |    1.117M              |    2.288G  |\n",
            "|    context_path.features.layer3.7           |    1.117M              |    2.288G  |\n",
            "|    context_path.features.layer3.8           |    1.117M              |    2.288G  |\n",
            "|    context_path.features.layer3.9           |    1.117M              |    2.288G  |\n",
            "|    context_path.features.layer3.10          |    1.117M              |    2.288G  |\n",
            "|    context_path.features.layer3.11          |    1.117M              |    2.288G  |\n",
            "|    context_path.features.layer3.12          |    1.117M              |    2.288G  |\n",
            "|    context_path.features.layer3.13          |    1.117M              |    2.288G  |\n",
            "|    context_path.features.layer3.14          |    1.117M              |    2.288G  |\n",
            "|    context_path.features.layer3.15          |    1.117M              |    2.288G  |\n",
            "|    context_path.features.layer3.16          |    1.117M              |    2.288G  |\n",
            "|    context_path.features.layer3.17          |    1.117M              |    2.288G  |\n",
            "|    context_path.features.layer3.18          |    1.117M              |    2.288G  |\n",
            "|    context_path.features.layer3.19          |    1.117M              |    2.288G  |\n",
            "|    context_path.features.layer3.20          |    1.117M              |    2.288G  |\n",
            "|    context_path.features.layer3.21          |    1.117M              |    2.288G  |\n",
            "|    context_path.features.layer3.22          |    1.117M              |    2.288G  |\n",
            "|   context_path.features.layer4              |   14.965M              |   8.469G   |\n",
            "|    context_path.features.layer4.0           |    6.04M               |    3.899G  |\n",
            "|    context_path.features.layer4.1           |    4.463M              |    2.285G  |\n",
            "|    context_path.features.layer4.2           |    4.463M              |    2.285G  |\n",
            "|   context_path.features.fc                  |   2.049M               |            |\n",
            "|    context_path.features.fc.weight          |    (1000, 2048)        |            |\n",
            "|    context_path.features.fc.bias            |    (1000,)             |            |\n",
            "|  attention_refinement_module1               |  1.052M                |  3.148M    |\n",
            "|   attention_refinement_module1.conv         |   1.05M                |   1.049M   |\n",
            "|    attention_refinement_module1.conv.weight |    (1024, 1024, 1, 1)  |            |\n",
            "|    attention_refinement_module1.conv.bias   |    (1024,)             |            |\n",
            "|   attention_refinement_module1.bn           |   2.048K               |   2.048K   |\n",
            "|    attention_refinement_module1.bn.weight   |    (1024,)             |            |\n",
            "|    attention_refinement_module1.bn.bias     |    (1024,)             |            |\n",
            "|   attention_refinement_module1.avgpool      |                        |   2.097M   |\n",
            "|  attention_refinement_module2               |  4.2M                  |  5.247M    |\n",
            "|   attention_refinement_module2.conv         |   4.196M               |   4.194M   |\n",
            "|    attention_refinement_module2.conv.weight |    (2048, 2048, 1, 1)  |            |\n",
            "|    attention_refinement_module2.conv.bias   |    (2048,)             |            |\n",
            "|   attention_refinement_module2.bn           |   4.096K               |   4.096K   |\n",
            "|    attention_refinement_module2.bn.weight   |    (2048,)             |            |\n",
            "|    attention_refinement_module2.bn.bias     |    (2048,)             |            |\n",
            "|   attention_refinement_module2.avgpool      |                        |   1.049M   |\n",
            "|  supervision1                               |  19.475K               |            |\n",
            "|   supervision1.weight                       |   (19, 1024, 1, 1)     |            |\n",
            "|   supervision1.bias                         |   (19,)                |            |\n",
            "|  supervision2                               |  38.931K               |            |\n",
            "|   supervision2.weight                       |   (19, 2048, 1, 1)     |            |\n",
            "|   supervision2.bias                         |   (19,)                |            |\n",
            "|  feature_fusion_module                      |  0.57M                 |  4.662G    |\n",
            "|   feature_fusion_module.convblock           |   0.569M               |   4.662G   |\n",
            "|    feature_fusion_module.convblock.conv1    |    0.569M              |    4.662G  |\n",
            "|    feature_fusion_module.convblock.bn       |    38                  |    0.311M  |\n",
            "|   feature_fusion_module.conv1               |   0.38K                |   0.361K   |\n",
            "|    feature_fusion_module.conv1.weight       |    (19, 19, 1, 1)      |            |\n",
            "|    feature_fusion_module.conv1.bias         |    (19,)               |            |\n",
            "|   feature_fusion_module.conv2               |   0.38K                |   0.361K   |\n",
            "|    feature_fusion_module.conv2.weight       |    (19, 19, 1, 1)      |            |\n",
            "|    feature_fusion_module.conv2.bias         |    (19,)               |            |\n",
            "|   feature_fusion_module.avgpool             |                        |   0.156M   |\n",
            "|  conv                                       |  0.38K                 |  0.189G    |\n",
            "|   conv.weight                               |   (19, 19, 1, 1)       |            |\n",
            "|   conv.bias                                 |   (19,)                |            |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Measure FLOPs and parameters using torchprofile\n",
        "dummy_input = torch.randn(1, 3, 1024,512).to(device)\n",
        "model.eval()\n",
        "flops = torchprofile.profile_macs(model, args=(dummy_input,))\n",
        "\n",
        "params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "print(f' flops={flops}\\n params={params} ')\n"
      ],
      "metadata": {
        "id": "ljOeeMI_Qlp6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bf6540b-8f39-452a-b3d1-2fc05c623169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " flops=91739513573\n",
            " params=50801192 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Google Mounting for Saving and Loading model**"
      ],
      "metadata": {
        "id": "YzK3ao5A0j0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from posixpath import isdir\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/Drive')\n",
        "get_ipython().system('/content/Drive/MyDrive/Checkpoints/BiSeNet/lr0.001b4')"
      ],
      "metadata": {
        "id": "u5JGDA3jrpX5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11384c16-d02b-4952-a2df-2ee7f927df70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/Drive; to attempt to forcibly remount, call drive.mount(\"/content/Drive\", force_remount=True).\n",
            "/bin/bash: line 1: /content/Drive/MyDrive/Checkpoints/BiSeNet/lr0.001b4: Is a directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Functions for Saving and Loading Model**"
      ],
      "metadata": {
        "id": "aMtKvnOEugHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to save the model\n",
        "def save_checkpoint(epoch, model, optimizer, save_dir='/content/Drive/MyDrive/Checkpoints/BiSeNet/lr0.001b4'):\n",
        "    # Ensure the save directory exists\n",
        "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Define the model filename with the epoch number\n",
        "    checkpoint_filename = f'checkpoint_epoch_{epoch}.pth'\n",
        "    checkpoint_path = os.path.join(save_dir, checkpoint_filename)\n",
        "\n",
        "    # Save the model and optimizer state dictionaries\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, checkpoint_path)\n",
        "    print(f'Model and optimizer saved to {checkpoint_path}')\n",
        "\n",
        "# Function to load the model\n",
        "def load_checkpoint(epoch, model, optimizer, save_dir='/content/Drive/MyDrive/Checkpoints/BiSeNet/lr0.001b4'):\n",
        "    checkpoint_filename = f'checkpoint_epoch_{epoch}.pth'\n",
        "    checkpoint_path = os.path.join(save_dir, checkpoint_filename)\n",
        "\n",
        "    # Check if the file exists\n",
        "    if not os.path.isfile(checkpoint_path):\n",
        "        raise FileNotFoundError(f\"The specified file was not found: {checkpoint_path}\")\n",
        "\n",
        "    # Load the model and optimizer state dictionaries\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch']\n",
        "\n",
        "    print(f'Model and optimizer loaded from {checkpoint_path}, resuming at epoch {start_epoch}')\n",
        "    return model, optimizer, start_epoch\n",
        "\n"
      ],
      "metadata": {
        "id": "1hgP366Auk-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lMpHUqlvulCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training with  Saving and Loading**"
      ],
      "metadata": {
        "id": "9Iwy_KA5TNwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#train loop\n",
        "# Resume training from the last checkpoint if available\n",
        "resume_training =False   # Set this to True if you want to resume training\n",
        "\n",
        "epochs = 50 # Set this to the total number of epochs you want to train\n",
        "\n",
        "if resume_training:\n",
        "    epoch_to_resume =0  #9,19,29,39,49  # Set this to the epoch from which you want to resume\n",
        "    try:\n",
        "        model, optimizer, start_epoch = load_checkpoint(epoch_to_resume, model, optimizer)\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(e)\n",
        "        start_epoch = 0\n",
        "else:\n",
        "    start_epoch = 0\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(start_epoch, epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    miou_metric.reset()\n",
        "    counter = 1\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs[0], labels.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "       # print(counter)\n",
        "        counter += 1\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        miou_metric.update(outputs[0].argmax(dim=1), labels)\n",
        "\n",
        "    # Save the model every 10 epochs\n",
        "    if (epoch+1) % 2 == 0:\n",
        "        save_checkpoint(epoch, model, optimizer)\n",
        "\n",
        "    miou = miou_metric.compute().item()\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader)}, Train mIoU: {miou}')\n",
        "\n",
        "# Measure latency after training\n",
        "latency = measure_latency(model, dummy_input)\n",
        "print(f\"Latency: {latency:.6f} seconds\")\n",
        "\n",
        "print(\"Training completed!\")\n"
      ],
      "metadata": {
        "id": "P8iDHubdrIAg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c5562b-b63c-4dcd-b38b-433a057c3899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/25], Loss: 0.2509793897488797, Train mIoU: 0.6345367431640625\n",
            "Model and optimizer saved to /content/Drive/MyDrive/Checkpoints/BiSeNet/lr0.001b4/checkpoint_epoch_1.pth\n",
            "Epoch [2/25], Loss: 0.06755324712843082, Train mIoU: 0.8064769506454468\n",
            "Epoch [3/25], Loss: 0.05943826178406334, Train mIoU: 0.8195066452026367\n",
            "Model and optimizer saved to /content/Drive/MyDrive/Checkpoints/BiSeNet/lr0.001b4/checkpoint_epoch_3.pth\n",
            "Epoch [4/25], Loss: 0.05521218296680742, Train mIoU: 0.8543257713317871\n",
            "Epoch [5/25], Loss: 0.0442639616467343, Train mIoU: 0.8882071375846863\n",
            "Model and optimizer saved to /content/Drive/MyDrive/Checkpoints/BiSeNet/lr0.001b4/checkpoint_epoch_5.pth\n",
            "Epoch [6/25], Loss: 0.04951994480806907, Train mIoU: 0.8538397550582886\n",
            "Epoch [7/25], Loss: 0.05276249669511203, Train mIoU: 0.8542620539665222\n",
            "Model and optimizer saved to /content/Drive/MyDrive/Checkpoints/BiSeNet/lr0.001b4/checkpoint_epoch_7.pth\n",
            "Epoch [8/25], Loss: 0.04654219327139036, Train mIoU: 0.8778607845306396\n",
            "Epoch [9/25], Loss: 0.047674576901183784, Train mIoU: 0.8834262490272522\n",
            "Model and optimizer saved to /content/Drive/MyDrive/Checkpoints/BiSeNet/lr0.001b4/checkpoint_epoch_9.pth\n",
            "Epoch [10/25], Loss: 0.055953534822389676, Train mIoU: 0.8299866318702698\n",
            "Epoch [11/25], Loss: 0.04665448544570659, Train mIoU: 0.8631851077079773\n",
            "Model and optimizer saved to /content/Drive/MyDrive/Checkpoints/BiSeNet/lr0.001b4/checkpoint_epoch_11.pth\n",
            "Epoch [12/25], Loss: 0.04107412700150304, Train mIoU: 0.8960627317428589\n",
            "Epoch [13/25], Loss: 0.04313619313026961, Train mIoU: 0.8709076642990112\n",
            "Model and optimizer saved to /content/Drive/MyDrive/Checkpoints/BiSeNet/lr0.001b4/checkpoint_epoch_13.pth\n",
            "Epoch [14/25], Loss: 0.03998474646881033, Train mIoU: 0.8925934433937073\n",
            "Epoch [15/25], Loss: 0.038528314727635786, Train mIoU: 0.8960392475128174\n",
            "Model and optimizer saved to /content/Drive/MyDrive/Checkpoints/BiSeNet/lr0.001b4/checkpoint_epoch_15.pth\n",
            "Epoch [16/25], Loss: 0.03715364416023247, Train mIoU: 0.9042180776596069\n",
            "Epoch [17/25], Loss: 0.03578981502649893, Train mIoU: 0.907074511051178\n",
            "Model and optimizer saved to /content/Drive/MyDrive/Checkpoints/BiSeNet/lr0.001b4/checkpoint_epoch_17.pth\n",
            "Epoch [18/25], Loss: 0.048893810915772544, Train mIoU: 0.8634518384933472\n",
            "Epoch [19/25], Loss: 0.04579976228546854, Train mIoU: 0.8679349422454834\n",
            "Model and optimizer saved to /content/Drive/MyDrive/Checkpoints/BiSeNet/lr0.001b4/checkpoint_epoch_19.pth\n",
            "Epoch [20/25], Loss: 0.03961991747893374, Train mIoU: 0.8932693600654602\n",
            "Epoch [21/25], Loss: 0.03664085604060849, Train mIoU: 0.9064059257507324\n",
            "Model and optimizer saved to /content/Drive/MyDrive/Checkpoints/BiSeNet/lr0.001b4/checkpoint_epoch_21.pth\n",
            "Epoch [22/25], Loss: 0.049070441521912735, Train mIoU: 0.8563181161880493\n",
            "Epoch [23/25], Loss: 0.04167405683689445, Train mIoU: 0.8626819252967834\n",
            "Model and optimizer saved to /content/Drive/MyDrive/Checkpoints/BiSeNet/lr0.001b4/checkpoint_epoch_23.pth\n",
            "Epoch [24/25], Loss: 0.036718116859898314, Train mIoU: 0.8998533487319946\n",
            "Epoch [25/25], Loss: 0.03521740083457101, Train mIoU: 0.9091942310333252\n",
            "Latency: 0.059877 seconds\n",
            "Training completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test Loader**"
      ],
      "metadata": {
        "id": "OpQ67CRAKM-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a transform if you need to preprocess the images\n",
        "transformed_dataset = CityscapesDataset(root_dir='/content/Drive/MyDrive/Cityscapes/Cityspaces/gtFine/val',\n",
        "im_transform=transforms.Compose([\n",
        "\n",
        "transforms.ToTensor(),\n",
        "transforms.Resize(test_resolution),\n",
        "\n",
        "]), )\n",
        "\n",
        "\n",
        "test_loader = DataLoader(transformed_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q8F7HxrMSK3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference and mIoU calculation on test set**"
      ],
      "metadata": {
        "id": "AZ3uZ37_S_5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "model.eval()\n",
        "miou_metric.reset()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "\n",
        "\n",
        "       #labels = labels.squeeze(0)\n",
        "\n",
        "\n",
        "\n",
        "        miou_metric.update(outputs.argmax(dim=1), labels)\n",
        "\n",
        "miou = miou_metric.compute().item()\n",
        "print(f'Test mIoU: {miou}')\n"
      ],
      "metadata": {
        "id": "KZd3_wXY4DbS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db375ed6-7e3b-4f7c-da9c-0c8450e60020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test mIoU: 0.8992522358894348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NkSs0iVQ_Vox"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}